{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data, combine train and test data,separate time information\n",
    "dfs = {}\n",
    "for name in ['train', 'test']:\n",
    "#     df = pd.read_csv('C:\\Users/Administrator/Desktop/Kaggle/data/%s.csv' % name)\n",
    "    df = pd.read_csv('Data/%s.csv' %name)\n",
    "    df['_data'] = name\n",
    "    dfs[name] = df\n",
    "\n",
    "df = dfs['train'].append(dfs['test'])\n",
    "\n",
    "dt = pd.DatetimeIndex(df['dteday'])\n",
    "df['day'] = dt.day\n",
    "df['dow'] = dt.dayofweek\n",
    "df['woy'] = dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logarithmic transformation to do error calculation\n",
    "df['cnt_log'] = np.log(df['cnt'] + 1)\n",
    "\n",
    "# add a by_season_all column which represents all renting bikes by season\n",
    "by_season = df[df['_data'] == 'train'].groupby('season')[['cnt']].agg(sum)\n",
    "by_season.columns = ['by_season_all']\n",
    "df = df.join(by_season, on='season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      _data   atemp    cnt      dteday  holiday  hr   hum  instant  mnth  \\\n",
      "0     train  0.2879   16.0  2011-01-01        0   0  0.81        1     1   \n",
      "1     train  0.2727   40.0  2011-01-01        0   1  0.80        2     1   \n",
      "2     train  0.2727   32.0  2011-01-01        0   2  0.80        3     1   \n",
      "3     train  0.2879   13.0  2011-01-01        0   3  0.75        4     1   \n",
      "4     train  0.2879    1.0  2011-01-01        0   4  0.75        5     1   \n",
      "5     train  0.2576    1.0  2011-01-01        0   5  0.75        6     1   \n",
      "6     train  0.2727    2.0  2011-01-01        0   6  0.80        7     1   \n",
      "7     train  0.2576    3.0  2011-01-01        0   7  0.86        8     1   \n",
      "8     train  0.2879    8.0  2011-01-01        0   8  0.75        9     1   \n",
      "9     train  0.3485   14.0  2011-01-01        0   9  0.76       10     1   \n",
      "10    train  0.3939   36.0  2011-01-01        0  10  0.76       11     1   \n",
      "11    train  0.3333   56.0  2011-01-01        0  11  0.81       12     1   \n",
      "12    train  0.4242   84.0  2011-01-01        0  12  0.77       13     1   \n",
      "13    train  0.4545   94.0  2011-01-01        0  13  0.72       14     1   \n",
      "14    train  0.4545  106.0  2011-01-01        0  14  0.72       15     1   \n",
      "15    train  0.4394  110.0  2011-01-01        0  15  0.77       16     1   \n",
      "16    train  0.4242   93.0  2011-01-01        0  16  0.82       17     1   \n",
      "17    train  0.4394   67.0  2011-01-01        0  17  0.82       18     1   \n",
      "18    train  0.4242   35.0  2011-01-01        0  18  0.88       19     1   \n",
      "19    train  0.4242   37.0  2011-01-01        0  19  0.88       20     1   \n",
      "20    train  0.4091   36.0  2011-01-01        0  20  0.87       21     1   \n",
      "21    train  0.4091   34.0  2011-01-01        0  21  0.87       22     1   \n",
      "22    train  0.4091   28.0  2011-01-01        0  22  0.94       23     1   \n",
      "23    train  0.4545   39.0  2011-01-01        0  23  0.88       24     1   \n",
      "24    train  0.4545   17.0  2011-01-02        0   0  0.88       25     1   \n",
      "25    train  0.4394   17.0  2011-01-02        0   1  0.94       26     1   \n",
      "26    train  0.4242    9.0  2011-01-02        0   2  1.00       27     1   \n",
      "27    train  0.4545    6.0  2011-01-02        0   3  0.94       28     1   \n",
      "28    train  0.4545    3.0  2011-01-02        0   4  0.94       29     1   \n",
      "29    train  0.4242    2.0  2011-01-02        0   6  0.77       30     1   \n",
      "...     ...     ...    ...         ...      ...  ..   ...      ...   ...   \n",
      "6463   test  0.2121    NaN  2012-12-30        0  18  0.44    17350    12   \n",
      "6464   test  0.3636    NaN  2012-12-30        0  19  0.61    17351    12   \n",
      "6465   test  0.1970    NaN  2012-12-30        0  20  0.47    17352    12   \n",
      "6466   test  0.2121    NaN  2012-12-30        0  21  0.51    17353    12   \n",
      "6467   test  0.1970    NaN  2012-12-30        0  22  0.55    17354    12   \n",
      "6468   test  0.1970    NaN  2012-12-30        0  23  0.51    17355    12   \n",
      "6469   test  0.1818    NaN  2012-12-31        0   0  0.55    17356    12   \n",
      "6470   test  0.1818    NaN  2012-12-31        0   1  0.55    17357    12   \n",
      "6471   test  0.1667    NaN  2012-12-31        0   2  0.59    17358    12   \n",
      "6472   test  0.1818    NaN  2012-12-31        0   3  0.59    17359    12   \n",
      "6473   test  0.1667    NaN  2012-12-31        0   4  0.69    17360    12   \n",
      "6474   test  0.1515    NaN  2012-12-31        0   5  0.64    17361    12   \n",
      "6475   test  0.1667    NaN  2012-12-31        0   6  0.64    17362    12   \n",
      "6476   test  0.1818    NaN  2012-12-31        0   7  0.64    17363    12   \n",
      "6477   test  0.1515    NaN  2012-12-31        0   8  0.69    17364    12   \n",
      "6478   test  0.2121    NaN  2012-12-31        0   9  0.64    17365    12   \n",
      "6479   test  0.2121    NaN  2012-12-31        0  10  0.69    17366    12   \n",
      "6480   test  0.2273    NaN  2012-12-31        0  11  0.60    17367    12   \n",
      "6481   test  0.2273    NaN  2012-12-31        0  12  0.56    17368    12   \n",
      "6482   test  0.2576    NaN  2012-12-31        0  13  0.44    17369    12   \n",
      "6483   test  0.2727    NaN  2012-12-31        0  14  0.45    17370    12   \n",
      "6484   test  0.2879    NaN  2012-12-31        0  15  0.45    17371    12   \n",
      "6485   test  0.2576    NaN  2012-12-31        0  16  0.48    17372    12   \n",
      "6486   test  0.2879    NaN  2012-12-31        0  17  0.48    17373    12   \n",
      "6487   test  0.2727    NaN  2012-12-31        0  18  0.48    17374    12   \n",
      "6488   test  0.2576    NaN  2012-12-31        0  19  0.60    17375    12   \n",
      "6489   test  0.2576    NaN  2012-12-31        0  20  0.60    17376    12   \n",
      "6490   test  0.2576    NaN  2012-12-31        0  21  0.60    17377    12   \n",
      "6491   test  0.2727    NaN  2012-12-31        0  22  0.56    17378    12   \n",
      "6492   test  0.2727    NaN  2012-12-31        0  23  0.65    17379    12   \n",
      "\n",
      "      season ...  ideal  wet  w1  w2  w3  w4  s1  s2  s3  s4  \n",
      "0          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "1          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "2          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "3          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "4          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "5          1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "7          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "8          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "9          1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "10         1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "11         1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "12         1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "13         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "14         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "15         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "16         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "17         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "18         1 ...      0    0   0   0   1   0   1   0   0   0  \n",
      "19         1 ...      0    0   0   0   1   0   1   0   0   0  \n",
      "20         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "21         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "22         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "23         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "24         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "25         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "26         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "27         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "28         1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "29         1 ...      0    0   0   0   1   0   1   0   0   0  \n",
      "...      ... ...    ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "6463       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6464       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6465       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6466       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6467       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6468       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6469       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6470       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6471       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6472       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6473       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "6474       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "6475       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "6476       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "6477       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "6478       1 ...      0    1   0   1   0   0   1   0   0   0  \n",
      "6479       1 ...      0    1   0   1   0   0   1   0   0   0  \n",
      "6480       1 ...      0    1   0   1   0   0   1   0   0   0  \n",
      "6481       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6482       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6483       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6484       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6485       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6486       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6487       1 ...      0    0   0   1   0   0   1   0   0   0  \n",
      "6488       1 ...      0    1   0   1   0   0   1   0   0   0  \n",
      "6489       1 ...      0    1   0   1   0   0   1   0   0   0  \n",
      "6490       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "6491       1 ...      0    0   1   0   0   0   1   0   0   0  \n",
      "6492       1 ...      0    1   1   0   0   0   1   0   0   0  \n",
      "\n",
      "[17379 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# add another feature discussed before, it shows peaks of bike-renting number\n",
    "df['peak'] = df[['hr', 'workingday']].apply(lambda x: (0, 1)[(x['workingday'] == 1 and  ( x['hr'] == 8 or 17 <= x['hr'] <= 18 or 12 <= x['hr'] <= 12)) or (x['workingday'] == 0 and  10 <= x['hr'] <= 19)], axis = 1)\n",
    "\n",
    "# add features to show special climate, this idea is from a blog \n",
    "df['ideal'] = df[['temp', 'windspeed']].apply(lambda x: (0, 1)[x['temp'] > 0.6 and x['windspeed'] < 0.44778], axis = 1)\n",
    "df['wet'] = df[['hum', 'workingday']].apply(lambda x: (0, 1)[x['workingday'] == 1 and x['hum'] >= 0.6], axis = 1)\n",
    "\n",
    "# test for mutual exclusiveness for weathersit\n",
    "df['w1'] = df[['weathersit']].apply(lambda x: (0,1)[x['weathersit'] == 1],axis = 1)\n",
    "df['w2'] = df[['weathersit']].apply(lambda x: (0,1)[x['weathersit'] == 2],axis = 1)\n",
    "df['w3'] = df[['weathersit']].apply(lambda x: (0,1)[x['weathersit'] == 3],axis = 1)\n",
    "df['w4'] = df[['weathersit']].apply(lambda x: (0,1)[x['weathersit'] == 4],axis = 1)\n",
    "\n",
    "# test for mutual exclusiveness for seasons\n",
    "df['s1'] = df[['season']].apply(lambda x: (0,1)[x['season'] == 1],axis = 1)\n",
    "df['s2'] = df[['season']].apply(lambda x: (0,1)[x['season'] == 2],axis = 1)\n",
    "df['s3'] = df[['season']].apply(lambda x: (0,1)[x['season'] == 3],axis = 1)\n",
    "df['s4'] = df[['season']].apply(lambda x: (0,1)[x['season'] == 4],axis = 1)\n",
    "\n",
    "\n",
    "print(df)\n",
    "# df.to_csv('Data/dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = df[df['_data'] == 'train'].copy()\n",
    "    return data\n",
    "\n",
    "def get_error(y_pred, y_actual):\n",
    "    difference = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(difference).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "def get_feature_and_result(data, input_cols):\n",
    "    X = data[input_cols].as_matrix()\n",
    "    y = data['cnt_log'].as_matrix()\n",
    "    return X, y\n",
    "def train_test_split(data):\n",
    "    train = data[data['day'] <= 14]\n",
    "    test = data[data['day'] > 14 ]\n",
    "    return train, test\n",
    "\n",
    "# similar functions have been given during the lab\n",
    "def predict_on_validation_set(model, input_cols):\n",
    "    data = get_data()\n",
    "    train, test = train_test_split(data)\n",
    "    X_train, y_train = get_feature_and_result(train, input_cols)\n",
    "    X_test, y_test = get_feature_and_result(test, input_cols)\n",
    "    my_model = model.fit(X_train, y_train)\n",
    "    y_pred = np.exp(my_model.predict(X_test))-1\n",
    "    y_pred_last = np.round(y_pred)\n",
    "    y_pred_last[y_pred_last < 0] = 0\n",
    "    y_test_last = np.exp(y_test)-1\n",
    "    score = get_error(y_pred_last, y_test_last)\n",
    "    return (y_pred_last, y_test_last, score)\n",
    "\n",
    "df_test = df[df['_data'] == 'test'].copy()\n",
    "\n",
    "def predict_on_test_set(model, input_cols):\n",
    "    df_train = df[df['_data'] == 'train'].copy()\n",
    "    X_train = df_train[input_cols].as_matrix()\n",
    "    y_train = df_train['cnt_log'].as_matrix()\n",
    "    X_test = df_test[input_cols].as_matrix()\n",
    "    my_model = model.fit(X_train, y_train)\n",
    "    y_pred = my_model.predict(X_test)\n",
    "    y_pred = np.exp(y_pred)-1\n",
    "    return y_pred\n",
    "\n",
    "def scoring_on_validation_set(model, input_cols):\n",
    "    pred = []\n",
    "    data = get_data()\n",
    "    train, test = train_test_split(data)\n",
    "    \n",
    "    X_train, y_train = get_feature_and_result(train, input_cols)\n",
    "    X_test, y_test = get_feature_and_result(test, input_cols)\n",
    "#     my_model = model.fit(X_train, y_train)\n",
    "    \n",
    "    cv = cross_validation.ShuffleSplit(n=len(train),n_iter=10, random_state=0)\n",
    "\n",
    "    scores_shuffle = np.abs(cross_validation.cross_val_score(model, X_train, y_train, cv=cv))\n",
    "    scores_shuffle_MAE = np.abs(cross_validation.cross_val_score(model, X_train, y_train, cv=cv, scoring = 'mean_absolute_error'))\n",
    "    scores_shuffle_MSE = np.abs(cross_validation.cross_val_score(model, X_train, y_train, cv=cv, scoring = 'mean_squared_error'))\n",
    "    scores_shuffle_MedianAE = np.abs(cross_validation.cross_val_score(model, X_train, y_train, cv=cv, scoring = 'median_absolute_error'))\n",
    "\n",
    "    print(\"R2 Accuracy: %0.2f (+/- %0.2f)\" % (scores_shuffle.mean(), scores_shuffle.std() * 2))\n",
    "    print(\"MAE Accuracy: %0.2f (+/- %0.2f)\" % (scores_shuffle_MAE.mean(), scores_shuffle_MAE.std() * 2))\n",
    "    print(\"MSE Accuracy: %0.2f (+/- %0.2f)\" % (scores_shuffle_MSE.mean(), scores_shuffle_MSE.std() * 2))\n",
    "    print(\"MedianAE Accuracy: %0.2f (+/- %0.2f)\" % (scores_shuffle_MedianAE.mean(), scores_shuffle_MedianAE.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Accuracy: 0.37 (+/- 0.15)\n",
      "MAE Accuracy: 0.81 (+/- 0.08)\n",
      "MSE Accuracy: 1.02 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.69 (+/- 0.11)\n",
      "R2 Accuracy: 0.39 (+/- 0.16)\n",
      "MAE Accuracy: 0.79 (+/- 0.09)\n",
      "MSE Accuracy: 0.99 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.65 (+/- 0.12)\n",
      "R2 Accuracy: 0.37 (+/- 0.15)\n",
      "MAE Accuracy: 0.81 (+/- 0.08)\n",
      "MSE Accuracy: 1.02 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.69 (+/- 0.11)\n",
      "R2 Accuracy: 0.39 (+/- 0.16)\n",
      "MAE Accuracy: 0.79 (+/- 0.08)\n",
      "MSE Accuracy: 0.98 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.66 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "linreg_cols = [\n",
    "    'weathersit', 'temp', 'wet', 'ideal', \n",
    "    'holiday', 'workingday', 'season', \n",
    "    'hr', 'dow', 'yr','mnth','woy'\n",
    "]\n",
    "# Split weather into 4\n",
    "linreg_cols1 = [\n",
    "    'w1', 'w1','w3','w4', 'temp', 'wet', 'ideal', \n",
    "    'holiday', 'workingday', 'season', \n",
    "    'hr', 'dow', 'yr','mnth','woy'\n",
    "]\n",
    "# Split seasons into 3\n",
    "linreg_cols2 = [\n",
    "    'weathersit', 'temp', 'wet', 'ideal', \n",
    "    'holiday', 'workingday', 's1', 's2', 's3', 's4', \n",
    "    'hr', 'dow', 'yr','mnth','woy'\n",
    "]\n",
    "# Split both\n",
    "linreg_cols3= [\n",
    "    'w1', 'w1','w3','w4', 'temp', 'wet', 'ideal', \n",
    "    'holiday', 'workingday','s1', 's2', 's3', 's4' , \n",
    "    'hr', 'dow', 'yr','mnth','woy'\n",
    "]\n",
    "\n",
    "\n",
    "reg_linreg_model = linear_model.Ridge(alpha = 0.4)\n",
    "\n",
    "(linreg_p, linreg_t, linreg_score) = predict_on_validation_set(linreg_model, linreg_cols)\n",
    "(linreg_p1, linreg_t1, linreg_score1) = predict_on_validation_set(reg_linreg_model, linreg_cols1)\n",
    "(linreg_p2, linreg_t2, linreg_score2) = predict_on_validation_set(reg_linreg_model, linreg_cols2)\n",
    "(linreg_p3, linreg_t3, linreg_score3) = predict_on_validation_set(reg_linreg_model, linreg_cols3)\n",
    "\n",
    "from sklearn import linear_model, preprocessing, grid_search, cross_validation, metrics\n",
    "\n",
    "scoring_on_validation_set(linreg_model, linreg_cols)\n",
    "scoring_on_validation_set(linreg_model, linreg_cols1)\n",
    "scoring_on_validation_set(linreg_model, linreg_cols2)\n",
    "scoring_on_validation_set(linreg_model, linreg_cols3)\n",
    "\n",
    "# print(linreg_score)\n",
    "# print(linreg_score1)\n",
    "# print(linreg_score2)\n",
    "# print(linreg_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ridge' object has no attribute 'alpha_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-41943a34d704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0malphas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_linreg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinreg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-41943a34d704>\u001b[0m in \u001b[0;36malphas\u001b[0;34m(model, input_cols)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_and_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_linreg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinreg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Ridge' object has no attribute 'alpha_'"
     ]
    }
   ],
   "source": [
    "reg_linreg_model = linear_model.RidgeCV(alphas=[1e-2, 1e-3,1e-4, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "\n",
    "def alphas(model, input_cols):\n",
    "    pred = []\n",
    "    data = get_data()\n",
    "    train, test = train_test_split(data)\n",
    "    \n",
    "    X_train, y_train = get_feature_and_result(train, input_cols)\n",
    "    X_test, y_test = get_feature_and_result(test, input_cols)\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.alpha_)\n",
    "    \n",
    "alphas(reg_linreg_model, linreg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "R2 Accuracy: 0.37 (+/- 0.15)\n",
      "MAE Accuracy: 0.81 (+/- 0.08)\n",
      "MSE Accuracy: 1.02 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.69 (+/- 0.11)\n",
      "R2 Accuracy: 0.39 (+/- 0.16)\n",
      "MAE Accuracy: 0.79 (+/- 0.08)\n",
      "MSE Accuracy: 0.98 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.65 (+/- 0.12)\n",
      "R2 Accuracy: 0.37 (+/- 0.15)\n",
      "MAE Accuracy: 0.81 (+/- 0.08)\n",
      "MSE Accuracy: 1.02 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.69 (+/- 0.11)\n",
      "R2 Accuracy: 0.39 (+/- 0.16)\n",
      "MAE Accuracy: 0.79 (+/- 0.08)\n",
      "MSE Accuracy: 0.98 (+/- 0.19)\n",
      "MedianAE Accuracy: 0.65 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "reg_linreg_model_lasso = linear_model.LassoCV(alphas=[1e-2, 1e-3,1e-4, 1e-5, 1e-6, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "alphas(reg_linreg_model_lasso, linreg_cols)\n",
    "\n",
    "reg_linreg_model_lasso_alpha = linear_model.Lasso(alpha=0.0001)\n",
    "scoring_on_validation_set(reg_linreg_model_lasso_alpha, linreg_cols)\n",
    "scoring_on_validation_set(reg_linreg_model_lasso_alpha, linreg_cols1)\n",
    "scoring_on_validation_set(reg_linreg_model_lasso_alpha, linreg_cols2)\n",
    "scoring_on_validation_set(reg_linreg_model_lasso_alpha, linreg_cols3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_model = linear_model.Lasso(alpha=0.0001)\n",
    "linreg_pred = predict_on_test_set(lasso_model, linreg_cols)\n",
    "y_pred = np.round(linreg_pred)\n",
    "df_test['Prediction'] = y_pred\n",
    "result = df_test[['dteday', 'Prediction']].copy()\n",
    "result.to_csv('Data/lasso_submit_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
